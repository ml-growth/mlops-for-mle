---
sidebar_position: 4
description: 📌 Docker Compose 를 이용해 zookeeper, kafka broker, schema-registry, connect 를 띄워봅니다.
---

# 4) Kafka System
import CodeDescription from '@site/src/components/CodeDescription';
import BrowserWindow from '@site/src/components/BrowserWindow';
import { Chapter, Part } from '@site/src/components/Highlight';
import ArchitectureImage from './img/kafka-13.png';

## 목표

1. Docker Compose 를 이용해 zookeeper, kafka broker, schema-registry, connect 를 띄워봅니다.

<details>
<summary>스펙 명세서</summary>
<CodeDescription>

### 스펙 명세서

1. Zookeeper 와 kafka broker 를 띄우는 `kafka-docker-compose.yaml` 파일을 작성합니다.
    - Zookeeper
        - Service name : `zookeeper`
        - Image : `confluentinc/cp-zookeeper:7.3.0`
        - Container name : `zookeeper`
        - Port : `2181:2181`
        - Environment
            - `ZOOKEEPER_SERVER_ID` : `1`
            - `ZOOKEEPER_CLIENT_PORT` : `2181`
    - Broker
        - Service name : `broker`
        - Image : `confluentinc/cp-kafka:7.3.0`
        - Container name : `broker`
        - Port : `9092:9092`
        - Environment
            - `KAFKA_BROKER_ID` : `1`
            - `KAFKA_ZOOKEEPER_CONNECT` : `zookeeper:2181`
            - `KAFKA_ADVERTISED_LISTENERS` : `PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092`
            - `KAFKA_LISTENER_SECURITY_PROTOCOL_MAP` : `PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT`
            - `KAFKA_INTER_BROKER_LISTENER_NAME` : `PLAINTEXT`
            - `KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR` : `1`
            - `KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS` : `0`
    - Schema-registry
        - Service name : `schema-registry`
        - Image : `confluentinc/cp-schema-registry:7.3.0`
        - Container name : `schema-registry`
        - Port : `8081:8081`
        - Environment
            - `SCHEMA_REGISTRY_HOST_NAME` : `schema-registry`
            - `SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS` : `broker:29092`
            - `SCHEMA_REGISTRY_LISTENERS` : `http://schema-registry:8081`
    - Connect
        - Service name : `connect`
        - Image : `confluentinc/cp-connect:7.3.0` 를 이용한 Dockerfile
            - Environment
                - `CONNECT_PLUGIN_PATH` : `“/usr/share/java,/usr/share/confluent-hub-components”`
            - Run
                - `confluent-hub install --no-prompt snowflakeinc/snowflake-kafka-connector:1.5.5`
                - `confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.2.2`
                - `confluent-hub install --no-prompt confluentinc/kafka-connect-json-schema-converter:7.3.0`
        - Container name : `connect`
        - Port : `8083:8083`
        - Environment
            - `CONNECT_BOOTSTRAP_SERVERS` : `schema-registry`
            - `CONNECT_BOOTSTRAP_SERVERS` : `broker:29092`
            - `CONNECT_REST_ADVERTISED_HOST_NAME` : `connect`
            - `CONNECT_GROUP_ID` : `docker-connect-group`
            - `CONNECT_CONFIG_STORAGE_TOPIC` : `docker-connect-configs`
            - `CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR` : `1`
            - `CONNECT_OFFSET_STORAGE_TOPIC` : `docker-connect-offsets`
            - `CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR` : `1`
            - `CONNECT_STATUS_STORAGE_TOPIC` : `docker-connect-status`
            - `CONNECT_STATUS_STORAGE_REPLICATION_FACTOR` : `1`
            - `CONNECT_KEY_CONVERTER` : `org.apache.kafka.connect.storage.StringConverter`
            - `CONNECT_VALUE_CONVERTER` : `org.apache.kafka.connect.json.JsonConverter`
            - `CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL` : `http://schema-registry:8081`
2. `kafka-docker-compose.yaml` 을 실행합니다.
3. `docker ps` 명령어를 이용하여 잘 띄워졌는지 확인합니다.

</CodeDescription>
</details>

---

<BrowserWindow url="https://github.com/mlops-for-mle/mlops-for-mle/tree/main/ch7">

해당 파트의 전체 코드는 [mlops-for-mle/ch7/](https://github.com/mlops-for-mle/mlops-for-mle/tree/main/ch7) 에서 확인할 수 있습니다.

```js
ch7
├── Makefile
├── README.md
// highlight-next-line
├── connect.Dockerfile
├── create_table.py
// highlight-next-line
├── kafka-docker-compose.yaml
├── naive-docker-compose.yaml
├── sink_connector.json
├── source_connector.json
├── target-docker-compose.yaml
└── target.Dockerfile
```

</BrowserWindow>

## 0. 환경 설정
:::caution

📌 이번 챕터를 진행하기 위해서는 위해서 앞서 <Chapter>2) Producer & Consumer</Chapter> 챕터에서 실행된 docker compose 를 종료해야 합니다.
:::

아래 명령어를 통해 종료합니다.

```bash
# terminal-command
docker compose -p ch7-naive down -v
```

## 1. Architecture

[그림 7-13]은 이번 실습에서 다룰 서비스들의 다이어그램입니다.

<div style={{textAlign: 'center'}}>

<img src={ArchitectureImage} style={{scale: '80%'}}/>
[그림7-13] Kafka System

</div>

각각의 서비스에 대해 알아보겠습니다.

- **Kafka Cluster** : source connector 에서 데이터를 받아 topic 에 저장하고, sink connector 로 넘겨줄 kafka cluster 입니다. broker 는 multi broker 가 아닌 single broker 를 사용하겠습니다.
- **Zookeeper** : broker server 의 상태 감지를 위해 사용되는 zookeeper server 입니다.
- **Schema Registry** : 메시지의 schema 를 저장하기 위한 schema registry server 입니다.
- **Kafka Connect** : connector 를 띄우기 위한 connect server 입니다.

이제 서비스를 하나씩 구체적으로 살펴보겠습니다.

## 2. Kafka Cluster

### 2.1 Zookeeper & Broker

zookeeper 와 broker 를 띄우는 코드는 <Chapter>2) Producer & Consumer</Chapter> 챕터에서 작성한 내용을 사용합니다.

```yaml  title="kafka-docker-compose.yaml"
version: "3"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
  broker:
    image: confluentinc/cp-kafka:7.3.0
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
```

### 2.2 Schema-registry

다음으로 schema-registry 를 띄우는 코드에 대해 알아보겠습니다.

<CodeDescription>

```yaml  title="kafka-docker-compose.yaml"
  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.0
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081
```

- `image` : schema-registry 의 이미지로 `confluentinc/cp-schema-registry:7.3.0` 를 이용하도록 하겠습니다.
- `container_name` : container의 이름은 `schema-registry` 로 사용하겠습니다.
- `depends_on` : `broker` 가 먼저 실행된 후 schema-registry 실행되어야 합니다.
- `ports` : schema-registry 의 포트인 `8081:8081` 을 포트포워딩합니다.

schema-registry 의 환경 변수는 다음과 같습니다.

<CodeDescription>

- **SCHEMA_REGISTRY_HOST_NAME**
  - schema-registry 의 host name 을 지정합니다.
  - 이번 챕터에서는 `schema-registry` 로 지정하겠습니다.
- **SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS**
  - bootstrap 으로 띄워진 broker server 를 지정합니다.
  - 일반적으로 `<broker service name>:<broker service internal port>` 형식으로 작성합니다.
  - 이번 챕터에서는 `broker:29092` 을 사용하겠습니다.
- **SCHEMA_REGISTRY_LISTENERS**
  - 외부에서 접속할 리스너를 설정합니다.
  - 이번 챕터에서는 `http://schema-registry:8081` 으로 설정하겠습니다.

</CodeDescription>

</CodeDescription>

### 2.3 Connect

다음으로 connect 를 띄우는 코드에 대해 알아보겠습니다.

Connect 의 경우 image 를 build 하기 위한 `Dockerfile` 이 필요합니다.
Dockerfile 은 아래와 같이 작성할 수 있습니다.

<CodeDescription>

```docker  title="connect.Dockerfile"
# connect.Dockerfile
FROM confluentinc/cp-kafka-connect:7.3.0

ENV CONNECT_PLUGIN_PATH="/usr/share/java,/usr/share/confluent-hub-components"

RUN confluent-hub install --no-prompt snowflakeinc/snowflake-kafka-connector:1.5.5 &&\
  confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.2.2 &&\
  confluent-hub install --no-prompt confluentinc/kafka-connect-json-schema-converter:7.3.0
```

- `FROM` : base image 로 `confluentinc/cp-kafka-connect:7.3.0` 을 사용하겠습니다.
- `ENV` : Connect 에서는 플러그인의 path 를 설정해주어야합니다.
  여기서는 base image 에 있는 `/usr/share/java` path 와 `/usr/share/confluent-hub-components` path 를 플러그인 path 로 설정합니다. 합쳐서  `"/usr/share/java,/usr/share/confluent-hub-components"` 플러그인 path 로 사용하겠습니다.
- `RUN` : 다음으로 image 를 만들 때 실행할 코드를 지정합니다. 여기서는 JDBC connector 를 사용할 것이며, PostgreSQL 에 접근이 가능한 connector 를 설치해야합니다. 또한 value schema 의 converter 는 json converter 를 사용하겠습니다. 따라서 환경 변수로 설정한 플러그인 path 를 통해 아래의 3가지 명령어를 사용하여 connector 와 converter 에 필요한 기능들을 설치합니다.
    - `confluent-hub install --no-prompt snowflakeinc/snowflake-kafka-connector:1.5.5`
    - `confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.2.2`
    - `confluent-hub install --no-prompt confluentinc/kafka-connect-json-schema-converter:7.3.0`

</CodeDescription>

앞서 작성한 Dockerfile 을 이용한 connect 의 코드는 아래와 같습니다.

<CodeDescription>

```yaml  title="kafka-docker-compose.yaml"
  connect:
    build:
      context: .
      dockerfile: connect.Dockerfile
    container_name: connect
    depends_on:
      - broker
      - schema-registry
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: docker-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
```

- `build` : `Dockerfile` 을 build 하기 위해 경로로 `.` 을 `dockerfile` 파일명인 `connect.Dockerfile` 을 입력합니다.
- `container_name` : container 의 이름으로 `connect` 로 사용하겠습니다.
- `depends_on` : `broker` 와 `schema-registry` 가 먼저 실행된 다음에 connect 가 실행되야 합니다.
- `ports` : connect 의 port 인 `8083:8083` 를 포트포워딩합니다.

Connect 의 환경 변수는 다음과 같습니다.

<CodeDescription>

- **CONNECT_BOOTSTRAP_SERVERS**
  - bootstrap 으로 띄워진 broker server 를 지정합니다.
  - 일반적으로  `<broker service name>:<broker service internal port>` 형식을 사용합니다.
- **CONNECT_REST_ADVERTISED_HOST_NAME**
  - kafka broker 에서 bootstrap 으로 띄워진 server 를 지정합니다.
  - 일반적으로  `<broker service name>:<broker service internal port>` 형식을 사용합니다.
- **CONNECT_GROUP_ID**
  - connect cluster 그룹에서 각각의 connect 를 식별할 때 필요한 ID 를 지정합니다.
- **CONNECT_CONFIG_STORAGE_TOPIC**
  - connector config 를 저장할 broker 의 topic 명을 설정합니다.
- **CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR**
  - config 를 저장하는 topic 을 생성할 때 사용할 replication factor 를 지정합니다.
  - 이번 챕터에서는 `1`로 설정하겠습니다.
- **CONNECT_OFFSET_STORAGE_TOPIC**
  - connector offset 을 저장할 broker 의 topic 명을 설정합니다.
- **CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR**
  - offset 을 저장하는 topic 을 생성할 때 사용할 replication factor 를 지정합니다.
  - 이번 챕터에서는 `1`로 설정하겠습니다.
- **CONNECT_STATUS_STORAGE_TOPIC**
  - connector 와 task 의 상태를 저장할 broker 의 topic 명을 설정합니다.
- **CONNECT_STATUS_STORAGE_REPLICATION_FACTOR**
  - 상태를 저장하는 topic 을 생성할 때 사용할 replication factor 를 지정합니다.
  - 이번 챕터에서는 `1`로 설정하겠습니다.
- **CONNECT_KEY_CONVERTER**
  - key 에 대한 converter 를 설정합니다.
  - 이번 챕터에서는 string converter 를 사용하겠습니다. 그래서 `org.apache.kafka.connect.storage.StringConverter` 를 기입해줍니다.
- **CONNECT_VALUE_CONVERTER**
  - value 에 대한 converter 를 설정합니다.
  - 이번 챕터에서는 json converter 를 사용하겠습니다. 그래서 `org.apache.kafka.connect.json.JsonConverter` 를 기입해줍니다.
- **CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL**
  - value converter 에 대한 schema registry url 를 설정합니다.
  - 이번 챕터에서는 앞서 살펴본 schema registry 의 service name 과 port 인 `http://schema-registry:8081` 를 기입해줍니다.

</CodeDescription>
</CodeDescription>

### 2.4 전체 코드

모든 서비스를 띄우는 코드는 아래와 같습니다.

```yaml
# kafka-docker-compose.yaml
version: "3"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181

  broker:
    image: confluentinc/cp-kafka:7.3.0
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.0
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092
      SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081

  connect:
    build:
      context: .
      dockerfile: connect.Dockerfile
    container_name: connect
    depends_on:
      - broker
      - schema-registry
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: docker-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

networks:
  default:
    name: mlops-network
    external: true
```

## 3. 실행

### 3.1 실행

`docker compose` 명령어를 이용하여 위에서 작성한 서비스들을 띄워봅니다.

<CodeDescription>

```bash
# terminal-command
docker compose -p ch7-kafka -f kafka-docker-compose.yaml up -d
```

- `-p` : project name 을 `ch7-kafka` 로 사용합니다.
- `-f` :file name 은 위에서 작성한 파일 이름인 `kafka-docker-compose.yaml`을 적어줍니다.

</CodeDescription>

### 3.2 실행 확인

`docker ps` 명령어를 이용하여 서비스들이 잘 띄워졌는지 확인합니다.

```bash
# terminal-command
docker ps
CONTAINER ID   IMAGE                                   COMMAND                  CREATED          STATUS                             PORTS                                        NAMES
2fe161195b13   ch7-kafka-connect                       "/etc/confluent/dock…"   41 seconds ago   Up 39 seconds (health: starting)   0.0.0.0:8083->8083/tcp, 9092/tcp             connect
4b98228b7e77   confluentinc/cp-schema-registry:7.3.0   "/etc/confluent/dock…"   41 seconds ago   Up 39 seconds                      0.0.0.0:8081->8081/tcp                       schema-registry
505d3a4d6fdb   confluentinc/cp-kafka:7.3.0             "/etc/confluent/dock…"   41 seconds ago   Up 40 seconds                      0.0.0.0:9092->9092/tcp                       broker
7f4a6f51837c   confluentinc/cp-zookeeper:7.3.0         "/etc/confluent/dock…"   42 seconds ago   Up 40 seconds                      2888/tcp, 0.0.0.0:2181->2181/tcp, 3888/tcp   zookeeper
```
