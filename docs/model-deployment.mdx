---
sidebar_position: 5
---
# 04. Model Deployment
import Highlight from '@site/src/components/Highlight';

## Request Driven - API Serving

학습이 완료된 모델을 다른 사람이 사용하게 하려면 어떻게 해야 할까요?
예를 들어서 개와 고양이를 분류할 수 있는 모델을 학습하고, 누군가 이 모델을 통해 개와 고양이를 분류하고 싶어 하는 상황을 가정해 봅시다.

단순하게 생각하면 저장된 모델과 추론에 사용된 코드를 사용자 에게 전달하고, 사용자는 전달 받은 모델과 코드를 이용해 예측할 수 있을 것 입니다.
위의 예에서는 개와 고양이를 분류하고 싶은 사람에게 학습된 모델과 코드를 전달하면 됩니다. 그런데 만약 추론하고자 하는 데이터가 핸드폰에서 촬영한 사진이며, 이를 핸드폰 에서 바로 분류하고 싶다면 전달 받은 내용으로 사용하기는 힘들 것입니다.
이 경우처럼 전달 받은 사람의 디바이스 환경에 따라 모델이 너무 커서 불러올 수 없거나, 설치된 패키지 버전이 달라 지는 등의 문제가 발생한다면 모델을 사용할 수 없습니다.

그럼 반대로 모델을 사용하고 싶은 사람이 데이터만 준다면 어떨까요? 위의 예에서는 개 또는 고양이를 찍은 사진을 우리에게 전송하고 우리가 직접 모델을 돌려서 결과를 전달하게 됩니다. 그럼 적어도 모델을 사용하고 싶은 사람이 직접 모델을 돌려야 할 때 생기는 문제들은 해결이 됩니다. 즉, 요청이 오면 해당 요청에 대한 응답을 하는 방식으로 이와 같은 방식은 비단 머신러닝 모델 뿐만 아니라 많은 소프트웨어에서 사용하는 방법입니다.
이러한 방법을 Request-Response 방식이라고 부릅니다.

디바이스끼리 Request - Response 를 하기 위해서는 어떻게 요청하고 어떻게 답변할지에 대해서 사전에 정의 하는 절차가 필요 합니다. 이러한 방법 중 가장 대표적인 것이 바로 REST API 입니다.

<Highlight color="#6A77D7">05. FastAPI</Highlight> 파트에서는 REST API 를 구현하는 오픈 소스중 가장 대중적인 FastAPI를 학습합니다. 
그리고 <Highlight color="#6A77D7">06. API Serving</Highlight> 파트에서는 REST API 를 통해 모델을 사용하여 결과를 얻는 API Serving 에 대해서 학습합니다.

## Event Driven - Stream Serving

만약, 데이터가 계속해서 쌓이고 있는 상황이라면 어떻게 될까요?
예를 들어서 공장에서 어떤 센서가 부착되어 있고 센서는 정해진 주기마다 계속해서 데이터를 수집하고 저장하고 있습니다. 그리고 이러한 데이터에 대해서 이상 탐지를 할 수 있는 모델을 서빙해야 하는 상황입니다.

이러한 상황을 쉽게 생각해보면 데이터를 수집하고 있는 곳에서 모델에게 계속해서 요청을 보내 결과를 받아오면 될 것 같습니다. 하지만 이 방법은 여러 문제를 갖고 있습니다. 수집하는 센서는 보통 아주 작은 단위의 업무만 처리할 수 있기에 요청을 보낼 수 없는 경우가 많습니다. 또한 요청을 통해 결과를 받는 주체가 아닌 경우가 많습니다. 이를 해결하기 위해서 대신 요청을 보내고 결과를 수집하는 주체가 필요합니다. 

위의 상황의 데이터를 수집하고 요청을 보내고 결과를 수집하는 상황을 Stream 이라고 표현합니다. 이를 위한 인프라로 주로 다루는 Kafka 를 7장에서 학습을 하며 모델에 요청을 보내서 수집하는 Stream Serving 을 8장에서 다룹니다.
