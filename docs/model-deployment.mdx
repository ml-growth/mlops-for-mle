---
sidebar_position: 5
---
# 04. Model Deployment

## Request Driven - API Serving

학습이 완료된 모델을 다른 사람이 사용하게 하려면 어떻게 해야 할까요?
예를 들어서 개와 고양이를 분류할 수 있는 모델을 학습했습니다. 어떤 사람이 이 모델을 통해 개와 고양이를 분류하고 싶어 하는 상황입니다.

쉽게 생각하면 저장된 모델과 사용 코드를 사용하고 싶은 사람에게 전달하고 받은 사람은 전달 받은 모델과 코드를 이용해 예측할 수 있습니다.
위의 예에서는 개와 고양이를 분류하고 싶은 사람에게 학습된 모델과 코드를 전달하면 됩니다. 그런데 만약 사진을 촬영한 핸드폰에서 분류하고 싶다면 전달 받은 모델을 사용하지 못할 것입니다.
이 경우처럼 전달 받은 사람의 디바이스에서 모델이 너무 커서 불러올 수 없거나 설치된 패키지 버전이 다르거나 등의 문제가 발생한다면  모델을 사용할 수 없습니다.

그럼 반대로 모델을 사용하고 싶은 사람이 데이터를 준다면 어떨까요? 위의 예에서는 개 또는 고양이를 찍은 사진을 우리에게 전송하고 우리가 직접 모델을 돌려서 결과를 전달합니다. 그럼 적어도 모델을 사용하고 싶은 사람이 직접 모델을 돌릴 때의 문제들은 해결이 됩니다. 즉, 요청이 오면 요청에 대한 답을 하는 방식인데 이와 같은 방식은 비단 머신러닝 모델 뿐만 아니라 많은 소프트웨어에서 사용하고 있습니다.
이러한 방법을 Request-Response 방식이라고 부릅니다.

디바이스끼리 Request - Response 를 하기 위해서는 어떻게 요청하고 어떻게 답변할지에 대해서 사전에 정의를 해야 합니다. 이러한 방법 중 가장 대표적인 것이 바로 REST API 입니다.

5장에서는 REST API 를 구현하는 오픈 소스중 가장 대중적인 FastAPI를 학습하며 6장에서는 모델을 이용할 수 있도록 하는 API Serving 에 대해서 학습합니다.

## Event Driven - Stream Serving

만약, 데이터가 계속해서 쌓이고 있는 상황이라면 어떻게 될까요?
예를 들어서 공장에서 어떤 센서가 부착되어 있고 센서는 정해진 주기마다 계속해서 데이터를 수집하고 저장하고 있습니다. 그리고 이러한 데이터에 대해서 이상 탐지를 할 수 있는 모델을 서빙해야 하는 상황입니다.

이러한 상황을 쉽게 생각해보면 데이터를 수집하고 있는 곳에서 모델에게 계속해서 요청을 보내 결과를 받아오면 될 것 같습니다. 하지만 이 방법은 여러 문제를 갖고 있습니다. 수집하는 센서는 보통 아주 작은 단위의 업무만 처리할 수 있기에 요청을 보낼 수 없는 경우가 많습니다. 또한 요청을 통해 결과를 받는 주체가 아닌 경우가 많습니다. 이를 해결하기 위해서 대신 요청을 보내고 결과를 수집하는 주체가 필요합니다. 

위의 상황의 데이터를 수집하고 요청을 보내고 결과를 수집하는 상황을 Stream 이라고 표현합니다. 이를 위한 인프라로 주로 다루는 Kafka 를 7장에서 학습을 하며 모델에 요청을 보내서 수집하는 Stream Serving 을 8장에서 다룹니다.
